{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67974f4f-6b95-4e78-a968-b4fa5eb528ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Create a discussion file path list\n",
    "discussion_file1_path = \"../Week1/DevGPT/snapshot_20230727/20230727_195954_discussion_sharings.json\"\n",
    "discussion_file2_path = \"../Week1/DevGPT/snapshot_20230803/20230803_094811_discussion_sharings.json\"\n",
    "discussion_file3_path = \"../Week1/DevGPT/snapshot_20230810/20230810_124048_discussion_sharings.json\"\n",
    "discussion_file4_path = \"../Week1/DevGPT/snapshot_20230817/20230817_130721_discussion_sharings.json\"\n",
    "discussion_file5_path = \"../Week1/DevGPT/snapshot_20230824/20230824_102000_discussion_sharings.json\"\n",
    "discussion_file6_path = \"../Week1/DevGPT/snapshot_20230831/20230831_061926_discussion_sharings.json\"\n",
    "\n",
    "discussion_json_files = [discussion_file1_path,discussion_file2_path,discussion_file3_path,discussion_file4_path,discussion_file5_path,discussion_file6_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24f9ff8f-fd66-4ecf-920d-51c8a1b8b708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an issue file path list\n",
    "issue_file1_path = \"../Week1/DevGPT/snapshot_20230727/20230727_195941_issue_sharings.json\"\n",
    "issue_file2_path = \"../Week1/DevGPT/snapshot_20230803/20230803_094705_issue_sharings.json\"\n",
    "issue_file3_path = \"../Week1/DevGPT/snapshot_20230810/20230810_123938_issue_sharings.json\"\n",
    "issue_file4_path = \"../Week1/DevGPT/snapshot_20230817/20230817_130502_issue_sharings.json\"\n",
    "issue_file5_path = \"../Week1/DevGPT/snapshot_20230824/20230824_101836_issue_sharings.json\"\n",
    "issue_file6_path = \"../Week1/DevGPT/snapshot_20230831/20230831_061759_issue_sharings.json\"\n",
    "\n",
    "issue_json_files = [issue_file1_path,issue_file2_path,issue_file3_path,issue_file4_path,issue_file5_path,issue_file6_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0801995-288c-49c7-9696-6b8f88328d64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Week1/DevGPT/snapshot_20230727/20230727_195954_discussion_sharings.json',\n",
       " '../Week1/DevGPT/snapshot_20230803/20230803_094811_discussion_sharings.json',\n",
       " '../Week1/DevGPT/snapshot_20230810/20230810_124048_discussion_sharings.json',\n",
       " '../Week1/DevGPT/snapshot_20230817/20230817_130721_discussion_sharings.json',\n",
       " '../Week1/DevGPT/snapshot_20230824/20230824_102000_discussion_sharings.json',\n",
       " '../Week1/DevGPT/snapshot_20230831/20230831_061926_discussion_sharings.json',\n",
       " '../Week1/DevGPT/snapshot_20230727/20230727_195941_issue_sharings.json',\n",
       " '../Week1/DevGPT/snapshot_20230803/20230803_094705_issue_sharings.json',\n",
       " '../Week1/DevGPT/snapshot_20230810/20230810_123938_issue_sharings.json',\n",
       " '../Week1/DevGPT/snapshot_20230817/20230817_130502_issue_sharings.json',\n",
       " '../Week1/DevGPT/snapshot_20230824/20230824_101836_issue_sharings.json',\n",
       " '../Week1/DevGPT/snapshot_20230831/20230831_061759_issue_sharings.json']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate two types of files\n",
    "json_files = discussion_json_files + issue_json_files\n",
    "json_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "609e09f5-c534-46be-aa9b-efa08f1625db",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File ../Week1/DevGPT/snapshot_20230727/20230727_195954_discussion_sharings.json does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m json_files:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;66;03m# load json files\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m         df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(file)\n\u001b[0;32m      7\u001b[0m         dataframes\u001b[38;5;241m.\u001b[39mappend(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSources\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mD:\\Opt\\anaconda3\\Lib\\site-packages\\pandas\\io\\json\\_json.py:791\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    789\u001b[0m     convert_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 791\u001b[0m json_reader \u001b[38;5;241m=\u001b[39m JsonReader(\n\u001b[0;32m    792\u001b[0m     path_or_buf,\n\u001b[0;32m    793\u001b[0m     orient\u001b[38;5;241m=\u001b[39morient,\n\u001b[0;32m    794\u001b[0m     typ\u001b[38;5;241m=\u001b[39mtyp,\n\u001b[0;32m    795\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    796\u001b[0m     convert_axes\u001b[38;5;241m=\u001b[39mconvert_axes,\n\u001b[0;32m    797\u001b[0m     convert_dates\u001b[38;5;241m=\u001b[39mconvert_dates,\n\u001b[0;32m    798\u001b[0m     keep_default_dates\u001b[38;5;241m=\u001b[39mkeep_default_dates,\n\u001b[0;32m    799\u001b[0m     precise_float\u001b[38;5;241m=\u001b[39mprecise_float,\n\u001b[0;32m    800\u001b[0m     date_unit\u001b[38;5;241m=\u001b[39mdate_unit,\n\u001b[0;32m    801\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    802\u001b[0m     lines\u001b[38;5;241m=\u001b[39mlines,\n\u001b[0;32m    803\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m    804\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m    805\u001b[0m     nrows\u001b[38;5;241m=\u001b[39mnrows,\n\u001b[0;32m    806\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    807\u001b[0m     encoding_errors\u001b[38;5;241m=\u001b[39mencoding_errors,\n\u001b[0;32m    808\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    809\u001b[0m     engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    810\u001b[0m )\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize:\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n",
      "File \u001b[1;32mD:\\Opt\\anaconda3\\Lib\\site-packages\\pandas\\io\\json\\_json.py:904\u001b[0m, in \u001b[0;36mJsonReader.__init__\u001b[1;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m filepath_or_buffer\n\u001b[0;32m    903\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mujson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 904\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data_from_filepath(filepath_or_buffer)\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_data(data)\n",
      "File \u001b[1;32mD:\\Opt\\anaconda3\\Lib\\site-packages\\pandas\\io\\json\\_json.py:960\u001b[0m, in \u001b[0;36mJsonReader._get_data_from_filepath\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m    952\u001b[0m     filepath_or_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    954\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m    955\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m filepath_or_buffer\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[0;32m    959\u001b[0m ):\n\u001b[1;32m--> 960\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_or_buffer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    962\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing literal json to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread_json\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. To read from a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    967\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    968\u001b[0m     )\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File ../Week1/DevGPT/snapshot_20230727/20230727_195954_discussion_sharings.json does not exist"
     ]
    }
   ],
   "source": [
    "# Load the data into DataFrame from all files \n",
    "dataframes = []\n",
    "for file in json_files:\n",
    "    try:\n",
    "        # load json files\n",
    "        df = pd.read_json(file)\n",
    "        dataframes.append(df[\"Sources\"])\n",
    "    except ValueError as e:\n",
    "        print(f\"error from {file} : {e}\")\n",
    "\n",
    "# combine all DataFrames\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "print(combined_df.info())\n",
    "print(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51710945-1a32-4386-8b18-aa797c7db4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract fields and transform the dataframe structure\n",
    "# create lists to collect target data\n",
    "Type_list = []\n",
    "RepoLanguage_list = []\n",
    "UpvoteCount_list = []\n",
    "Conversations_num_list = []\n",
    "Number_list = []\n",
    "# Traverse combined dataframe to extract target fields\n",
    "for i in range(0,len(combined_df)):\n",
    "    # extract Type data\n",
    "    Type_list.append(combined_df[i].get(\"Type\",' '))\n",
    "    # extract RepoLanguage data\n",
    "    RepoLanguage_list.append(combined_df[i].get(\"RepoLanguage\",'unknown'))\n",
    "    # extract Number data\n",
    "    Number_list.append(combined_df[i].get(\"Number\",0))\n",
    "    # extract UpvoteCount data\n",
    "    UpvoteCount_list.append(combined_df[i].get(\"UpvoteCount\",0))\n",
    "    # extract the number of total Conversations\n",
    "    ChatgptSharing = combined_df[i].get(\"ChatgptSharing\",0)\n",
    "    Conversations_num = 0\n",
    "    for item in ChatgptSharing:\n",
    "        Conversations = item.get(\"Conversations\",[])\n",
    "        Conversations_num +=len(Conversations)\n",
    "    \n",
    "    Conversations_num_list.append(Conversations_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4e490f-65b4-4693-89bf-2fbc85f54d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create transformed dataframe with extracted fields\n",
    "transformed_data = {\n",
    "    \"Type\":Type_list,\n",
    "    \"RepoLanguage\":RepoLanguage_list,\n",
    "    \"Number\":Number_list,\n",
    "    \"UpvoteCount\":UpvoteCount_list,\n",
    "    \"Conversations_num\":Conversations_num_list\n",
    "}\n",
    "transformed_df = pd.DataFrame(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc60f1de-0c3b-436e-90f7-5667e998734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93031122-fa92-4aa9-a3a0-91faa63c5657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the distribution of Type\n",
    "transformed_df[\"Type\"].value_counts().sort_values(ascending=False).plot(kind=\"bar\", color=\"skyblue\", figsize=(8, 6))\n",
    "\n",
    "plt.title(\"Value Counts of 'Type'\", fontsize=16)\n",
    "plt.xlabel(\"RepoLanguage\", fontsize=14)\n",
    "plt.ylabel(\"Frequency\", fontsize=14)\n",
    "\n",
    "transformed_df[\"Type\"].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e071461-1afc-4659-8ff2-ce44bd1c8e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the distribution of RepoLanguage\n",
    "transformed_df[\"RepoLanguage\"].value_counts().sort_values(ascending=False).plot(kind=\"bar\", color=\"skyblue\", figsize=(8, 6))\n",
    "\n",
    "plt.title(\"Value Counts of 'RepoLanguage'\", fontsize=16)\n",
    "plt.xlabel(\"RepoLanguage\", fontsize=14)\n",
    "plt.ylabel(\"Frequency\", fontsize=14)\n",
    "\n",
    "transformed_df[\"RepoLanguage\"].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d9d0dd-393a-4107-82a2-c537f996f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the distribution of Top 50 frequnt Number\n",
    "average_Number = transformed_df[\"Number\"].mean()\n",
    "print(\"Number Average:\", average_Number)\n",
    "\n",
    "transformed_df[\"Number\"].value_counts().sort_values(ascending=False).head(50).plot(kind=\"bar\", color=\"skyblue\", figsize=(8, 6))\n",
    "\n",
    "plt.title(\"Value Counts of 'Number'\", fontsize=16)\n",
    "plt.xlabel(\"Number\", fontsize=14)\n",
    "plt.xticks(fontsize=8, rotation=90)\n",
    "plt.ylabel(\"Frequency\", fontsize=14)\n",
    "transformed_df[\"Number\"].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae8996e-096c-419c-9987-39d4bb6d3c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the distribution of UpvoteCount\n",
    "average_UpvoteCount = transformed_df[\"UpvoteCount\"].mean()\n",
    "print(\"UpvoteCount Average:\", average_UpvoteCount)\n",
    "\n",
    "transformed_df[\"UpvoteCount\"].value_counts().sort_values(ascending=False).plot(kind=\"bar\", color=\"skyblue\", figsize=(8, 6))\n",
    "\n",
    "plt.title(\"Value Counts of 'UpvoteCount'\", fontsize=16)\n",
    "plt.xlabel(\"UpvoteCount\", fontsize=14)\n",
    "plt.ylabel(\"Frequency\", fontsize=14)\n",
    "\n",
    "transformed_df[\"UpvoteCount\"].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64e48c5-ffab-4b53-8285-b4c242aeb482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the distribution of Conversations_num\n",
    "average_conversations = transformed_df[\"Conversations_num\"].mean()\n",
    "print(\"Conversations_num Average:\", average_conversations)\n",
    "transformed_df[\"Conversations_num\"].value_counts().sort_values(ascending=False).plot(kind=\"bar\", color=\"skyblue\", figsize=(8, 6))\n",
    "\n",
    "plt.title(\"Value Counts of 'Conversations_num'\", fontsize=16)\n",
    "plt.xlabel(\"Conversations_num\", fontsize=14)\n",
    "plt.ylabel(\"Frequency\", fontsize=14)\n",
    "\n",
    "transformed_df[\"Conversations_num\"].value_counts().sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
